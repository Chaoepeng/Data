# 5 内存管理

在内存管理方式上，Spark主要分堆内内存（On-heap Memory）和堆外内存（Off-heap Memory）。这里的“堆”指的是 JVM Heap，因此堆内内存实际上就是 Executor JVM 的堆内存；堆外内存指的是通过 Java Unsafe API，像 C++ 那样直接从操作系统中申请和释放内存空间。

spark on yarn 内存划分及相应参数
![image](https://user-images.githubusercontent.com/15443165/158096206-36990433-d05b-47e6-893f-f7cca6c069f9.png)

## 1、堆内内存(On-heap Memory)

以Spark on yarn为例，Spark Executor运行在Yarn Container 上，一般情况下，一个Yarn Container运行一个Executor，可以将Yarn Container看做Executor Container；Container 本质上也是JVM进程。

从广义上讲，Container的内存可以理解为堆内内存，由spark.executor.memory与spark.executor.memoryOverhead决定。

spark.executor.memoryOverhead是在yarn部署模式下，container会预留一部分内存，形式是堆外，用来保证稳定性，主要存储nio buffer，函数栈等一些开销，目的是保持运行时的稳定性，这个参数并不能提升spark的性能。

从狭义上讲，Container中spark.executor.memory决定的内存是堆内内存，是我们平常进行spark性能优化的重点。

spark 堆内内存划分模型
![image](https://user-images.githubusercontent.com/15443165/158096234-ef870742-4031-4fa2-9455-c0d1fa17ac98.png)

其中spark.executor.memory是绝对值，它指定了Executor进程的JVM Heap总大小。spark.memory.fraction（默认0.75）和spark.memory.storageFraction（默认0.5）都是比例值，它们指定了划定不同区域的空间占比。

spark.memory.fraction用于标记Spark处理分布式数据集的内存总大小，这部分内存包括Execution Memory和Storage Memory两部分。

spark.memory.storageFraction则用来进一步区分Execution Memory和Storage Memory的初始大小。

- User Memory：用户的内存区， 用于存储开发者自定义数据结构，大小是（M – 300）* （1 – mf）。
- Reserved Memory：系统预留内存，被用来存储各种 Spark 内部对象，例如存储系统中的 BlockManager、DiskBlockManager 等等，大小固定为300MB (spark.testing.reservedMemory)。
- Storage Memory：用来cache RDD数据，存储broadcast变量，大小是（M – 300）* mf * sf。
- Execution Memory：Spark计算使用内存，例如: join, shuffle, sorts, 和 aggregations等，大小是（M – 300）* mf * （1 – sf）。

## 2、堆外内存(Off-heap Memory)

spark 堆外内存划分模型
![image](https://user-images.githubusercontent.com/15443165/158096295-50212e39-26e3-4ddf-98d1-9792c2d666b7.png)

Spark 把堆外内存划分为两块区域：一块用于执行分布式任务，如 Shuffle、Sort 和 Aggregate 等操作，这部分内存叫做 Execution Memory；一块用于缓存 RDD 和广播变量等数据，它被称为 Storage Memory。

Execution Memory和Storage Memory占用的空间大小直接由参数spark.memory.storageFraction决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域。

在默认情况下堆外内存并不启用：
- 启用堆外内存：spark.memory.offHeap.enabled
- 设置堆外内存大小(maxOffHeapMemory)：spark.memory.offHeap.size ，单位为字节。

如果堆外内存被启用，那么 Executor 内将同时存在堆内和堆外内存，两者的使用互不影响，这个时候 Executor 中的 Execution 内存是堆内的 Execution 内存和堆外的 Execution 内存之和，同理，Storage 内存也一样。

**堆内、堆外是以Job为粒度划分的，也就是说，同一个Job，要么，你全用堆外，要么，你全用堆内。堆外、堆内的内存空间，是不能在同一个Job之内共享的。**

对于堆外内存来说，Spark 通过调用 Java Unsafe 的 allocateMemory 和 freeMemory 方法，直接在操作系统内存中申请、释放内存空间，可以减少不必要的内存开销，以及频繁的GC扫描和回收，提升了处理性能；但是管理成本较高。

对于堆内内存来说，无需 Spark 亲自操刀而是由 JVM 代理，但频繁的 JVM GC 对执行性能来说是一大隐患。另外，Spark 对堆内内存占用的预估往往不够精确，高估可用内存往往会为 OOM 埋下隐患。

## 3、动态占用机制–Execution&&Storage

spark1.6之后，spark引入统一内存管理UnifiedMemoryManager，动态调整Storage Memory和Execution Memory的大小，从而更充分地利用内存, 减少内存spill的次数。

在统一内存管理模式下，Execution Memory与Storage Memory之间可以互相抢占，主要有三条原则：
- 如果对方的内存空间有空闲，双方可以互相抢占；
- 对于Storage Memory抢占的Execution Memory部分，当分布式任务有计算需要时，Storage Memory必须立即归还抢占的内存，涉及的缓存数据要么落盘、要么清除；
- 对于Execution Memory抢占的Storage Memory部分，即便Storage Memory有收回内存的需要，也必须要等到分布式任务执行完毕才能释放。

## 4、内存分配示例

配置参数如下：

|  spark.executor.memory   | spark.memory.fraction  |  spark.memory.storageFraction  | spark.memory.offHeap.size  |
|  ----  | ----  | ----  | ----  |
| 18g  | 0.6  | 0.5  | 10g  |

**只启用堆内内存：**

上图很清楚地看到 Storage Memory 的可用内存是 10.1GB，这个数是咋来的呢？根据前面的规则，我们可以得出以下的计算：

    systemMemory = spark.executor.memory
    reservedMemory = 300MB
    usableMemory = systemMemory - reservedMemory
    StorageMemory= usableMemory * spark.memory.fraction * spark.memory.storageFraction

如果我们把数据代进去，得出以下的结果：

    systemMemory = 18Gb = 19327352832 字节
    reservedMemory = 300MB = 300 * 1024 * 1024 = 314572800
    usableMemory = systemMemory - reservedMemory = 19327352832 - 314572800 = 19012780032 
    StorageMemory= usableMemory * spark.memory.fraction * spark.memory.storageFraction= 19012780032 * 0.6 * 0.5 = 5703834009.6 = 5.312109375GB
    
不对啊，和上面的 10.1GB 对不上啊。为什么呢？这是因为 Spark UI 上面显示的 Storage Memory 可用内存其实等于 Execution 内存和 Storage 内存之和，也就是 usableMemory * spark.memory.fraction：

    StorageMemory= usableMemory * spark.memory.fraction= 19012780032 * 0.6 = 11407668019.2 = 10.62421GB

还是不对，这是因为我们虽然设置了 spark.executor.memory=18g，但是 Spark 的 Executor 端通过 Runtime.getRuntime.maxMemory 拿到的内存其实没这么大，只有 17179869184 字节，所以 

    systemMemory = 17179869184，然后计算的数据如下：
    systemMemory = 17179869184 字节
    reservedMemory = 300MB = 300 * 1024 * 1024 = 314572800
    usableMemory = systemMemory - reservedMemory = 17179869184 - 314572800 = 16865296384 
    StorageMemory= usableMemory * spark.memory.fraction= 16865296384 * 0.6 = 9.42421875 GB
    
我们通过将上面的 16865296384 * 0.6 字节除于 1024 * 1024 * 1024 转换成 9.42421875 GB，和 UI 上显示的还是对不上，这是因为 Spark UI 是通过除于 1000 * 1000 * 1000 将字节转换成 GB，如下：

    systemMemory = 17179869184 字节
    reservedMemory = 300MB = 300 * 1024 * 1024 = 314572800
    usableMemory = systemMemory - reservedMemory = 17179869184 - 314572800 = 16865296384 
    StorageMemory= usableMemory * spark.memory.fraction= 16865296384 * 0.6 字节 = 16865296384 * 0.6 / (1000 * 1000 * 1000) = 10.1GB
    
我们设置了 spark.executor.memory=18g，但是 Spark 的 Executor 端通过 Runtime.getRuntime.maxMemory 拿到的内存其实没这么大，只有 17179869184 字节，这个数据是怎么计算的？
Runtime.getRuntime.maxMemory 是程序能够使用的最大内存，其值会比实际配置的执行器内存的值小。这是因为内存分配池的堆部分分为 Eden，Survivor 和 Tenured 三部分空间，而这里面一共包含了两个 Survivor 区域，而这两个 Survivor 区域在任何时候我们只能用到其中一个，所以我们可以使用下面的公式进行描述：

    ExecutorMemory = Eden + 2 * Survivor + TenuredRuntime.getRuntime.maxMemory = Eden + Survivor + Tenured

上面的 17179869184 字节可能因为你的 GC 配置不一样得到的数据不一样，但是上面的计算公式是一样的。

**堆内内存+堆外内存：**

其实 Spark UI 上面显示的 Storage Memory 可用内存等于堆内内存和堆外内存之和，计算公式如下：

    堆内
    systemMemory = 17179869184 字节
    reservedMemory = 300MB = 300 * 1024 * 1024 = 314572800
    usableMemory = systemMemory - reservedMemory = 17179869184 - 314572800 = 16865296384 
    totalOnHeapStorageMemory = usableMemory * spark.memory.fraction= 16865296384 * 0.6 = 10119177830
    堆外
    totalOffHeapStorageMemory = spark.memory.offHeap.size = 10737418240

    StorageMemory 
    = totalOnHeapStorageMemory + totalOffHeapStorageMemory
    = (10119177830 + 10737418240) 字节
    = (20856596070 / (1000 * 1000 * 1000)) GB
    = 20.9 GB

