# 3 调度系统

  Spark 是典型的主从型（M/S，Master/Slave）架构，从系统的角度来看，Spark 分布式系统的核心进程只有两种：Driver 和 Executor，分别对应主从架构的 Master 和 Slave。
  
  在 Spark 分布式系统中，Driver 只有一个，而 Executor 可以有多个。
  
  Driver 提供 SparkContext（SparkSession）上下文环境，而上下文环境提供了 Spark 分布式系统所有的核心组件，如 RPC 系统、调度系统、存储系统、内存管理、Shuffle 管理等。
  
  Driver 通过这些核心组件来对分布式任务进行拆解、调度、分发、追踪与维护，俗称“指挥的”。
  
  Executor 主要负责分布式任务的执行和状态反馈，俗称“干活儿的”。

  **Spark 调度系统的核心职责是**：先将用户构建的 DAG 转化为分布式任务，结合分布式集群资源的可用性，基于调度规则依序把分布式任务分发到执行器。
  
  **Spark 调度系统的工作流程包含如下 5 个步骤：**
  
    1. 将 DAG 拆分为不同的运行阶段 Stages；

    2. 创建分布式任务 Tasks 和任务组 TaskSet；

    3. 获取集群内可用的硬件资源情况；

    4. 按照调度规则决定优先调度哪些任务/组；

    5. 依序将分布式任务分发到执行器 Executor。
    
   **调度系统中的核心组件有哪些？**
   
   Spark 调度系统包含 3 个核心组件，分别是 DAGScheduler、TaskScheduler 和 SchedulerBackend。这 3 个组件都运行在 Driver 进程中，它们通力合作将用户构建的 DAG 转化为分布式任务，再把这些任务分发给集群中的 Executors 去执行。
   
