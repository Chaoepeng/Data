# 4 存储系统 

Spark 存储系统用于存储 3 个方面的数据，分别是 RDD 缓存、Shuffle 中间文件、广播变量。

## 1、存储系统的基本组件有哪些？
BlockManager、BlockManagerMaster、MemoryStore、DiskStore 和 DiskBlockManager 等等。

BlockManager是其中最为重要的组件，BlockManager会运行在每个节点上，包括driver和executor。在Executors端负责统一管理和协调数据的本地存取与跨节点传输。

对外，BlockManager与Driver端的BlockManagerMaster通信，不仅定期向BlockManagerMaster汇报本地数据元信息，还会不定时按需拉取全局数据存储状态。
另外，不同Executors的BlockManager之间也会以Server/Client模式跨节点推送和拉取数据块。

对内，BlockManager通过组合存储系统内部组件的功能来实现数据的存与取、收与发。

BlockManager各个模块间的关系：
![blockManager](https://user-images.githubusercontent.com/15443165/158060526-8c2ae92c-9dfe-4648-b733-9d92e5e2b4dd.jpg)

Spark存储系统提供了两种存储抽象：**MemoryStore（内存）和DiskStore（磁盘）**。

- 广播变量的全量数据存储在Executors进程中，因此它由MemoryStore管理。

- Shuffle中间文件往往会落盘到本地节点，所以这些文件的落盘和访问就要经由DiskStore。

- RDD缓存支持内存缓存和磁盘缓存两种模式，缓存在内存中的数据会封装到MemoryStore，缓存在磁盘上的数据则交由DiskStore管理。

Spark存储系统支持两种数据类型：**对象值（Object Values）和字节数组（Byte Array）**。

MemoryStore可以存储字节数组（省空间）和对象（访问快）；DiskStore只能存储序列化后的字节数组。


## 2、透过RDD缓存看MemoryStore

MemoryStore同时支持存储对象值和字节数组这两种不同的数据形式，并且统一采用MemoryEntry数据抽象对它们进行封装。

MemoryEntry有两个实现类：DeserializedMemoryEntry和SerializedMemoryEntry，分别用于封装原始对象值和序列化之后的字节数组。DeserializedMemoryEntry用 Array[T]来存储对象值序列，其中T是对象类型，而SerializedMemoryEntry使用ByteBuffer来存储序列化后的字节序列。

利用MemoryStore在内存中缓存RDD数据内容
![image](https://user-images.githubusercontent.com/15443165/158060674-f60df9db-33d0-43bb-91a8-97c5d31a7108.png)

缓存RDD的过程，就是将RDD计算数据的迭代器（Iterator）进行物化的过程。要把RDD数据内容缓存下来，得先把RDD的迭代器展开成实实在在的数据值才行。

第一步就是通过调用putIteratorAsValues或是putIteratorAsBytes方法，把RDD迭代器展开为数据值，然后把这些数据值暂存到一个叫做ValuesHolder的数据结构里。这一步，我们通常把它叫做“Unroll”。

第二步，为了节省内存开销，我们可以在存储数据值的ValuesHolder上直接调用toArray或是toByteBuffer操作，把ValuesHolder转换为MemoryEntry数据结构。

注意：这一步的转换不涉及内存拷贝，也不产生额外的内存开销，因此Spark官方把这一步叫做“从Unroll memory到Storage memory的Transfer（转移）”。

第三步，这些包含RDD数据值的MemoryEntry和与之对应的BlockId，会被一起存入Key 为BlockId、Value 是MemoryEntry引用的链式哈希字典LinkedHashMap中。

因此，LinkedHashMap[BlockId, MemoryEntry]缓存的是关于数据存储的元数据，MemoryEntry才是真正保存RDD数据实体的存储单元。换句话说，大面积占用内存的不是哈希字典，而是一个又一个的MemoryEntry。

    为什么使用LinkedHashMap？
    当storage memory不足，spark需要删除rdd cache的时候，遵循的是LRU，利用LinkedHashMap的“访问有序”特性可以轻松实现LRU。

总的来说，RDD数据分片、Block和MemoryEntry三者之间是一一对应的，当所有的RDD数据分片都物化为MemoryEntry，并且所有的（Block ID, MemoryEntry）对都记录到LinkedHashMap字典之后，RDD就完成了数据缓存到内存的过程。

## 3、透过Shuffle看DiskStore

DiskStore 中数据的存取本质上就是字节序列与磁盘文件之间的转换，它通过 putBytes 方法把字节序列存入磁盘文件，再通过 getBytes 方法将文件内容转换为数据块。

Spark对磁盘文件的管理是通过DiskBlockManager来进行管理的，DiskBlockManager 的主要职责就是，记录逻辑数据块 Block 与磁盘文件系统中物理文件的对应关系，每个 Block 都对应一个磁盘文件。

DiskBlockManager 在初始化的时候，首先根据配置项 spark.local.dir 在磁盘的相应位置创建文件目录。然后，在 spark.local.dir 指定的所有目录下分别创建子目录，子目录的个数由配置项 spark.diskStore.subDirectories 控制，它默认是 64。所有这些目录均用于存储通过 DiskStore 进行物化的数据文件，如 RDD 缓存文件、Shuffle 中间结果文件等。

DiskStore 中数据的存与取
![image](https://user-images.githubusercontent.com/15443165/158060754-34eabe0c-874f-42b5-b5a5-6f6a5e297f9a.png)

**Spark 默认采用 SortShuffleManager 来管理 Stages 间的数据分发，在 Shuffle write 过程中，有 3 类结果文件：temp_shuffle_XXX、shuffle_XXX.data 和 shuffle_XXX.index。**

Data 文件存储分区数据，它是由 temp 文件合并而来的，而 index 文件记录 data 文件内不同分区的偏移地址。Shuffle 中间文件具体指的就是 data 文件和 index 文件，temp 文件作为暂存盘文件最终会被删除。

在 Shuffle write 的不同阶段，Shuffle manager 通过 BlockManager 调用 DiskStore 的 putBytes 方法将数据块写入文件。文件由 DiskBlockManager 创建，文件名就是 putBytes 方法中的 Block ID，这些文件会以“temp_shuffle”或“shuffle”开头，保存在 spark.local.dir 目录下的子目录里。

在 Shuffle read 阶段，Shuffle manager 再次通过 BlockManager 调用 DiskStore 的 getBytes 方法，读取 data 文件和 index 文件，将文件内容转化为数据块，最终这些数据块会通过网络分发到 Reducer 端进行聚合计算。

## 4、透过Broadcast看MemoryStore

![image](https://user-images.githubusercontent.com/15443165/158060830-076a58e4-ce18-429f-b2b3-d75d7926c626.png)

整个广播变量存入MemoryStore的流程如下：

1. TorrentBroadcast#writeBlocks()方法：将要广播的对象划分为多个blocks，并将这些blocks保存到BlockManager，主要通过blockManager#putBytes()方法来实现的；

2. blockManager#putBytes()方法通过调用 doPutBytes() 方法将序列化的bytes（ChunkedByteBuffer）通过指定的StorageLevel保存到 memoryStore 中；

3. 接下来，重点就在doPutBytes() 方法的实现，首先它会根据传入此方法中的 StorageLevel 来判断缓存是写入内存还是磁盘，也就是用 MemoryStore还是DiskStore来进行缓存；

4. 如果缓存级别中使用了内存，则会进一步通过缓存级别中有没有指定序列化来判断是存对象值序列还是字节序列。

（1）如果是deserialized（非序列化）的，就将bytes进行反序列化，然后调用 memoryStore#putIteratorAsValues()方法——>memoryStore#putIterator() 将block保存到MemoryStore，putIterator()方法中，可能会因为迭代器太大，无法物化存储在内存中。为了避免OOM异常，此方法将逐步展开迭代器，同时定期检查是否有足够的空闲内存。如果block被成功物化，那么物化期间使用的临时展开内存（unroll memory）将被“转移”到存储内存（StorageMemory），因此我们不会获得比存储块实际需要的更多的内存；

（2）如果是serialized（序列化）的，还会进一步判断内存模型（MemoryMode）是堆内存（ON_HEAP）还是非堆内存（ON_HEAP），是哪种内存模型，就申请对应的StorageMemory，并将bytes实例化为一个SerializedMemoryEntry放入entries（LinkedHashMap）。

5. 如果缓存级别中使用了磁盘，则会调用 diskStore#putBytes()进行数据的缓存。
